{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# export @src  thành 1 cái API của chatbot chưa có UI "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert your existing chatbot code into an API without a UI, you can use a framework like Flask. Below are the necessary changes to create a simple API for your chatbot. This will allow you to send requests to the chatbot and receive responses without a user interface.\n",
    "\n",
    "### Changes Overview\n",
    "1. **Create a Flask app** to handle incoming requests.\n",
    "2. **Define an endpoint** to receive user questions and return chatbot responses.\n",
    "3. **Remove Streamlit-specific code** since we are not using a UI.\n",
    "\n",
    "### Updated Code\n",
    "Here’s how you can modify your `src/server.py` file:\n",
    "\n",
    "```python:src/server.py\n",
    "from flask import Flask, request, jsonify  # Import Flask\n",
    "from rag_pipeline.back import LLMHandler, VectorDatabase, QuestionAnsweringChain\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Parameters\n",
    "load_dotenv()\n",
    "gemini_key = os.getenv('gemini_key')\n",
    "qdrant_key = os.getenv('qdrant_key')\n",
    "rerank = True\n",
    "rewrite = True\n",
    "num_docs = 5\n",
    "\n",
    "# Initialize components\n",
    "vector_db = VectorDatabase(\n",
    "    model_name=\"hiieu/halong_embedding\",\n",
    "    collection_name='cmc_final_db',\n",
    "    api=qdrant_key\n",
    ")\n",
    "llm_handler = LLMHandler(model_name=\"gemini-1.5-flash\", gemini_key=gemini_key)\n",
    "qa_chain = QuestionAnsweringChain(\n",
    "    llm_handler=llm_handler,\n",
    "    vector_db=vector_db,\n",
    "    num_docs=num_docs,\n",
    "    apply_rerank=rerank,\n",
    "    apply_rewrite=rewrite,\n",
    "    date_impact=0.001\n",
    ")\n",
    "\n",
    "@app.route('/chat', methods=['POST'])  # Define the chat endpoint\n",
    "def chat():\n",
    "    data = request.json\n",
    "    question = data.get('question')\n",
    "    \n",
    "    if not question:\n",
    "        return jsonify({\"error\": \"No question provided\"}), 400\n",
    "\n",
    "    # Get AI response\n",
    "    response, extracted_links = qa_chain.run(question)\n",
    "\n",
    "    return jsonify({\n",
    "        \"response\": response,\n",
    "        \"links\": extracted_links\n",
    "    })\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)  # Run the Flask app\n",
    "```\n",
    "\n",
    "### Explanation of Changes\n",
    "- **Flask Setup**: The code imports Flask and initializes a Flask app.\n",
    "- **Chat Endpoint**: A new endpoint `/chat` is created to handle POST requests. It expects a JSON body with a `question` field.\n",
    "- **Response Handling**: The chatbot's response and any extracted links are returned as a JSON response.\n",
    "- **Removed Streamlit Code**: All Streamlit-specific code has been removed since we are now using an API.\n",
    "\n",
    "### Running the API\n",
    "To run the API, make sure you have Flask installed. You can install it using:\n",
    "```bash\n",
    "pip install Flask\n",
    "```\n",
    "Then, run your server:\n",
    "```bash\n",
    "python src/server.py\n",
    "```\n",
    "\n",
    "You can now send POST requests to `http://127.0.0.1:5000/chat` with a JSON body like:\n",
    "```json\n",
    "{\n",
    "    \"question\": \"Your question here\"\n",
    "}\n",
    "```\n",
    "\n",
    "This will return a JSON response with the chatbot's answer and any related links.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
