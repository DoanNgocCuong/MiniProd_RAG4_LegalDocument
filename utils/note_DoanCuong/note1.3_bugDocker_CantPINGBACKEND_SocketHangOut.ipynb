{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Vẫn bug: POST http://127.0.0.1:25039/chat\n",
    "Error: socket hang up\n",
    "Request Headers\n",
    "Content-Type: application/json\n",
    "User-Agent: PostmanRuntime/7.43.0\n",
    "Accept: */*\n",
    "Cache-Control: no-cache\n",
    "Postman-Token: 91246568-07d1-4d86-8044-ef2e1d2e0853\n",
    "Host: 127.0.0.1:25039\n",
    "Accept-Encoding: gzip, deflate, br\n",
    "Connection: keep-alive\n",
    "Request Body\n",
    "\n",
    "\n",
    "\n",
    "Check @backend \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "OST http://127.0.0.1:25039/chat\n",
    "Error: connect ECONNREFUSED 127.0.0.1:25039\n",
    "Request Headers\n",
    "Content-Type: application/json\n",
    "User-Agent: PostmanRuntime/7.43.0\n",
    "Accept: */*\n",
    "Cache-Control: no-cache\n",
    "Postman-Token: ab0c86dd-e028-4539-aa5b-c5980abbbd19\n",
    "Host: 127.0.0.1:25039\n",
    "Accept-Encoding: gzip, deflate, br\n",
    "Connection: keep-alive\n",
    "Request Body\n",
    "\n",
    "\n",
    "BUG \n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "ed                                                                                                                                                  \n",
    "backend-1   | 2024-12-19 15:45:06,912 - WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused\n",
    "backend-1   | 2024-12-19 15:45:08,990 - WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused\n",
    "backend-1   | 2024-12-19 15:45:08,991 - WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.\n",
    "backend-1   | Traceback (most recent call last):                                                                                                    \n",
    "backend-1   |   File \"/app/app.py\", line 70, in <module>\n",
    "backend-1   |     initialize_components()                                                                                                           \n",
    "backend-1   |   File \"/app/app.py\", line 51, in initialize_components                                                                               \n",
    "backend-1   |     llm_handler = LLMHandler(                                                                                                         \n",
    "backend-1   |   File \"/app/rag_pipeline/back.py\", line 37, in __init__\n",
    "backend-1   |     self.llm = ChatGoogleGenerativeAI(model=model_name, api_key=self.api_key)                                                         \n",
    "backend-1   |   File \"/usr/local/lib/python3.9/site-packages/langchain_core/load/serializable.py\", line 125, in __init__                            \n",
    "backend-1   |     super().__init__(*args, **kwargs)                                                                                                 \n",
    "backend-1   |   File \"/usr/local/lib/python3.9/site-packages/pydantic/main.py\", line 214, in __init__                                               \n",
    "backend-1   |     validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n",
    "backend-1   |   File \"/usr/local/lib/python3.9/site-packages/langchain_google_genai/chat_models.py\", line 838, in validate_environment              \n",
    "backend-1   |     self.client = genaix.build_generative_service(                                                                                    \n",
    "backend-1   |   File \"/usr/local/lib/python3.9/site-packages/langchain_google_genai/_genai_extension.py\", line 276, in build_generative_service     \n",
    "backend-1   |     return v1betaGenerativeServiceClient(**config)\n",
    "backend-1   |   File \"/usr/local/lib/python3.9/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 687, in __init__                                                                                                                                          \n",
    "backend-1   |     self._transport = transport_init(\n",
    "backend-1   |   File \"/usr/local/lib/python3.9/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/grpc.py\", line 154, in __init__                                                                                                                                 \n",
    "backend-1   |     super().__init__(\n",
    "backend-1   |   File \"/usr/local/lib/python3.9/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/base.py\", line 100, in __init__                                                                                                                                 \n",
    "backend-1   |     credentials, _ = google.auth.default(\n",
    "backend-1   |   File \"/usr/local/lib/python3.9/site-packages/google/auth/_default.py\", line 697, in default                                         \n",
    "backend-1   |     raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)                                                          \n",
    "backend-1   | google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.                                                            \n",
    "backend-1 exited with code 0\n",
    "backend-1   | /app/rag_pipeline/back.py:43: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
    "backend-1   |   self.embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "backend-1   | 2024-12-19 15:45:16,270 - INFO - 🔄 Initializing components...                                                                        \n",
    "backend-1   | 2024-12-19 15:45:16,445 - INFO - Use pytorch device_name: cpu\n",
    "backend-1   | 2024-12-19 15:45:16,445 - INFO - Load pretrained SentenceTransformer: hiieu/halong_embedding\n",
    "backend-1   | /app/rag_pipeline/back.py:56: LangChainDeprecationWarning: The class `Qdrant` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-qdrant package and should be used instead. To use it run `pip install -U :class:`~langchain-qdrant` and import as `from :class:`~langchain_qdrant import Qdrant``.\n",
    "backend-1   |   return Qdrant(\n",
    "backend-1   | 2024-12-19 15:45:20,513 - INFO - ✅ Vector database initialized                                                                       \n",
    "backend-1   | 2024-12-19 15:45:20,520 - WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused                                                                                                                                                  \n",
    "backend-1   | 2024-12-19 15:45:21,528 - WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused\n",
    "backend-1   | 2024-12-19 15:45:23,501 - WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused\n",
    "backend-1   | 2024-12-19 15:45:23,501 - WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.\n",
    "backend-1   | Traceback (most recent call last):                                                                                                    \n",
    "backend-1   |   File \"/app/app.py\", line 70, in <module>\n",
    "backend-1   |     initialize_components()                                                                                                           \n",
    "backend-1   |   File \"/app/app.py\", line 51, in initialize_components                                                                               \n",
    "backend-1   |     llm_handler = LLMHandler(\n",
    "backend-1   |   File \"/app/rag_pipeline/back.py\", line 37, in __init__                                                                              \n",
    "backend-1   |     self.llm = ChatGoogleGenerativeAI(model=model_name, api_key=self.api_key)                                                         \n",
    "backend-1   |   File \"/usr/local/lib/python3.9/site-packages/langchain_core/load/serializable.py\", line 125, in __init__                            \n",
    "backend-1   |     super().__init__(*args, **kwargs)\n",
    "backend-1   |   File \"/usr/local/lib/python3.9/site-packages/pydantic/main.py\", line 214, in __init__                                               \n",
    "backend-1   |     validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)                                            \n",
    "backend-1   |   File \"/usr/local/lib/python3.9/site-packages/langchain_google_genai/chat_models.py\", line 838, in validate_environment\n",
    "backend-1   |     self.client = genaix.build_generative_service(                                                                                    \n",
    "backend-1   |   File \"/usr/local/lib/python3.9/site-packages/langchain_google_genai/_genai_extension.py\", line 276, in build_generative_service     \n",
    "backend-1   |     return v1betaGenerativeServiceClient(**config)                                                                                    \n",
    "backend-1   |   File \"/usr/local/lib/python3.9/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 687, in __init__                                                                                                                                          \n",
    "backend-1   |     self._transport = transport_init(\n",
    "backend-1   |   File \"/usr/local/lib/python3.9/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/grpc.py\", line 154, in __init__                                                                                                                                 \n",
    "backend-1   |     super().__init__(\n",
    "backend-1   |   File \"/usr/local/lib/python3.9/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/base.py\", line 100, in __init__                                                                                                                                 \n",
    "backend-1   |     credentials, _ = google.auth.default(\n",
    "backend-1   |   File \"/usr/local/lib/python3.9/site-packages/google/auth/_default.py\", line 697, in default                                         \n",
    "backend-1   |     raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n",
    "backend-1   | google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.                                                            \n",
    "backend-1 exited with code 0\n",
    "backend-1   | /app/rag_pipeline/back.py:43: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
    "backend-1   |   self.embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "backend-1   | 2024-12-19 15:45:31,649 - INFO - 🔄 Initializing components...                                                                        \n",
    "backend-1   | 2024-12-19 15:45:31,842 - INFO - Use pytorch device_name: cpu                                                                         \n",
    "backend-1   | 2024-12-19 15:45:31,843 - INFO - Load pretrained SentenceTransformer: hiieu/halong_embedding\n",
    "                                                                                                                                                    \n",
    "\n",
    "v View in Docker Desktop   o View Config   w Enable Watch\n",
    "```\n",
    "\n",
    "Bug: XÁC THỰC GOOGLE GÌ ĐÓ LÀM CHO ĐÓNG DOCKER KHÔNG PING ĐƯỢC BACKEND"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tôi sẽ tóm tắt các điểm chính về lỗi \"socket hang up\" từ các câu trả lời trên Stack Overflow:\n",
    "\n",
    "**Nguyên nhân phổ biến:**\n",
    "\n",
    "1. **Vấn đề HTTP/HTTPS:**\n",
    "- Ứng dụng đang chạy HTTPS nhưng request gửi qua HTTP\n",
    "- Cần đảm bảo protocol (http/https) khớp giữa client và server\n",
    "\n",
    "2. **Vấn đề Port:**\n",
    "- Port đang được sử dụng bởi service khác\n",
    "- Port bị block hoặc không được support bởi VPN/Proxy\n",
    "- Nên thử đổi port (ví dụ từ 8088 sang 8089)\n",
    "\n",
    "3. **Vấn đề Network:**\n",
    "- VPN đang bật có thể gây ra vấn đề\n",
    "- Proxy settings không phù hợp\n",
    "- Network isolation trong Docker\n",
    "\n",
    "4. **Vấn đề Timeout:**\n",
    "- Request chờ response quá lâu\n",
    "- Cần cấu hình timeout phù hợp\n",
    "- Có thể sử dụng HTTP 202 (Accepted) để handle long-running tasks\n",
    "\n",
    "5. **Headers và Content:**\n",
    "- Thiếu Content-Length header\n",
    "- Content-Type không phù hợp\n",
    "- Host header có vấn đề\n",
    "\n",
    "**Giải pháp cho Docker:**\n",
    "\n",
    "1. Kiểm tra và cấu hình network trong Docker:\n",
    "```yaml\n",
    "services:\n",
    "  backend:\n",
    "    networks:\n",
    "      - app_network\n",
    "    ports:\n",
    "      - \"3000:3000\"\n",
    "```\n",
    "\n",
    "2. Cấu hình resources limits:\n",
    "```yaml\n",
    "services:\n",
    "  backend:\n",
    "    deploy:\n",
    "      resources:\n",
    "        limits:\n",
    "          memory: 2G\n",
    "          cpus: '2'\n",
    "```\n",
    "\n",
    "3. Thêm health check:\n",
    "```yaml\n",
    "services:\n",
    "  backend:\n",
    "    healthcheck:\n",
    "      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:3000/health\"]\n",
    "      interval: 30s\n",
    "      timeout: 10s\n",
    "      retries: 3\n",
    "```\n",
    "\n",
    "4. Kiểm tra logs Docker để debug chi tiết hơn\n",
    "\n",
    "Đây là những giải pháp phổ biến nhất để xử lý lỗi \"socket hang up\" trong môi trường Docker.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
